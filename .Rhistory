data <- data[nrow(data):1,]
####representation de la série####
# On enlève les 4 dernière valeurs en vue de la prévision
T<-length(data$Date)
data<-data[-c((T-3), (T-2), (T-1), T),]
# Convertir la colonne "date" en format date et création d'une série de type zoo
data$Date <- seq(as.Date("1990-05-01"), as.Date("2023-01-01"), by = "1 month") # Convertir la colonne "date" en format date
xm <- zoo(data$Valeur) # convertit le premiers element de data en serie temporelle de type "zoo"
T <- length(xm)
#data$Date <- seq(as.Date("2023-01-01"), as.Date("1990-05-01"), by = "-1 month")
#xm <- zoo(data$Valeur, order.by=data$Date)
# représentation graphique
dxm <- diff(xm,1)
plot(cbind(xm,dxm))
ggplot( data, aes(y = xm, x = Date)) +
geom_line()
#ggplot( data, aes(y = xm, x = rev(data$Date))) +
#  geom_line()
####autocorrélation####
par(mfrow=c(1,2))
acf(xm); pacf(xm)
dev.off()
####Moyenne à 0#####
y <- xm - mean(xm)
par(mfrow=c(1,2))
plot(xm)
plot(y)
acf(y,30);pacf(y,30)
#### Test d'integration ####
summary(lm(xm ~ data$Date))
#Cette regression lineaire nous permets de determiner quel type de Dickey-Fuller test nous devons utiliser
#Ici, la constante est significative, et la time trend également,
#nous utiliserons donc  Test for a unit root with constant and deterministic time trend
adf <- adfTest(xm, lag=0, type="ct")
adf
#On rejette donc l'hypothese d'une racine unitaire avec une confiance d'au moins 95%
#On ajoute des differences de lag pour controler l'effet du passe sur la relation entre X_t_-_1 et X_t
Qtests <- function(series, k, fitdf=0) {
pvals <- apply(matrix(1:k), 1, FUN=function(l) {
pval <- if (l<=fitdf) NA else Box.test(series, lag=l, type="Ljung-Box", fitdf=fitdf)$p.value
return(c("lag"=l,"pval"=pval))
})
return(t(pvals))
}
Qtests(adf@test$lm$residuals, 50, fitdf = length(adf@test$lm$coefficients))
#Les résidus sont tous autocorrélés
adfTest_valid <- function(series, kmax, adftype){
k <- 0
noautocorr <- 0
while (noautocorr==0){
cat(paste0("ADF with ",k," lags: residuals OK? "))
adf <- adfTest(series, lags=k, type=adftype)
pvals <- Qtests(adf@test$lm$residuals, 24, fitdf = length(adf@test$lm$coefficients))[,2]
if (sum(pvals<0.05,na.rm=T)==0) {
noautocorr <- 1; cat("OK \n")
} else cat("nope \n")
k <- k+1
}
return(adf)
}
adf <- adfTest_valid(xm,350,adftype="ct")
adfTest_valid <- function(series, kmax, adftype){
k <- 0
noautocorr <- 0
while (noautocorr==0){
cat(paste0("ADF with ",k," lags: residuals OK? "))
adf <- adfTest(series, lags=k, type=adftype)
pvals <- Qtests(adf@test$lm$residuals, 390, fitdf = length(adf@test$lm$coefficients))[,2]
if (sum(pvals<0.05,na.rm=T)==0) {
noautocorr <- 1; cat("OK \n")
} else cat("nope \n")
k <- k+1
}
return(adf)
}
adf <- adfTest_valid(xm,350,adftype="ct")
warnings()
Qtests(adf@test$lm$residuals, 50, fitdf = length(adf@test$lm$coefficients))
adf <- adfTest(xm, lag=0, type="ct")
adf
summary(adf)
adf
Qtests <- function(series, k, fitdf=0) {
pvals <- apply(matrix(1:k), 1, FUN=function(l) {
pval <- if (l<=fitdf) NA else Box.test(series, lag=l, type="Ljung-Box", fitdf=fitdf)$p.value
return(c("lag"=l,"pval"=pval))
})
return(t(pvals))
}
adf <- adfTest(xm, lag=0, type="ct")
adf
Qtests <- function(series, k, fitdf=0) {
pvals <- apply(matrix(1:k), 1, FUN=function(l) {
pval <- if (l<=fitdf) NA else Box.test(series, lag=l, type="Ljung-Box", fitdf=fitdf)$p.value
return(c("lag"=l,"pval"=pval))
})
return(t(pvals))
}
Qtests(adf@test$lm$residuals, 50, fitdf = length(adf@test$lm$coefficients))
adfTest_valid <- function(series, kmax, adftype){
k <- 0
noautocorr <- 0
while (noautocorr==0){
cat(paste0("ADF with ",k," lags: residuals OK? "))
adf <- adfTest(series, lags=k, type=adftype)
pvals <- Qtests(adf@test$lm$residuals, kmax, fitdf = length(adf@test$lm$coefficients))[,2]
if (sum(pvals<0.05,na.rm=T)==0) {
noautocorr <- 1; cat("OK \n")
} else cat("nope \n")
k <- k+1
}
return(adf)
}
adf <- adfTest_valid(xm,350,adftype="ct")
adf <- adfTest_valid(xm,50,adftype="ct")
adf <- adfTest_valid(xm,393,adftype="ct")
Qtests(adf@test$lm$residuals, 393, fitdf = length(adf@test$lm$coefficients))
adf
Qtests(adf@test$lm$residuals, 393, fitdf = length(adf@test$lm$coefficients))
adf <- adfTest(xm, lags=393, type="ct")
adf <- adfTest(xm, lags=194, type="ct")
Qtests(adf@test$lm$residuals, 393, fitdf = length(adf@test$lm$coefficients))
Qtests(adf@test$lm$residuals, 393, fitdf = length(adf@test$lm$coefficients))
adf <- adfTest(xm, lag=0, type="ct")
adf
Qtests <- function(series, k, fitdf=0) {
pvals <- apply(matrix(1:k), 1, FUN=function(l) {
pval <- if (l<=fitdf) NA else Box.test(series, lag=l, type="Ljung-Box", fitdf=fitdf)$p.value
return(c("lag"=l,"pval"=pval))
})
return(t(pvals))
}
Qtests(adf@test$lm$residuals, 50, fitdf = length(adf@test$lm$coefficients))
adf@test$lm
rm(list = ls())
library(zoo) #format de serie temporelle pratique et facile d'utilisation (mais plus volumineux)
library(tseries) #diverses fonctions sur les series temporelles
library(ggplot2)
library(fUnitRoots)
####set-up####
path <- "/Users/ludovic/Desktop/ENSAE/S2/series/serie_temp"
setwd(path) #definit l'espace de travail (working directory ou "wd")
getwd() #affiche le wd
list.files() #liste les elements du wd
####import####
datafile <- "input/valeurs_serie.csv" #definit le fichier de donnees
data <- read.csv(datafile,sep = ";") #importe un fichier .csv dans un objet de classe data.frame
data <- data[nrow(data):1,]
####representation de la série####
# On enlève les 4 dernière valeurs en vue de la prévision
T<-length(data$Date)
data<-data[-c((T-3), (T-2), (T-1), T),]
# Convertir la colonne "date" en format date et création d'une série de type zoo
data$Date <- seq(as.Date("1990-05-01"), as.Date("2023-01-01"), by = "1 month") # Convertir la colonne "date" en format date
xm <- zoo(data$Valeur) # convertit le premiers element de data en serie temporelle de type "zoo"
T <- length(xm)
#data$Date <- seq(as.Date("2023-01-01"), as.Date("1990-05-01"), by = "-1 month")
#xm <- zoo(data$Valeur, order.by=data$Date)
# représentation graphique
dxm <- diff(xm,1)
plot(cbind(xm,dxm))
ggplot( data, aes(y = xm, x = Date)) +
geom_line()
#ggplot( data, aes(y = xm, x = rev(data$Date))) +
#  geom_line()
####autocorrélation####
par(mfrow=c(1,2))
acf(xm); pacf(xm)
dev.off()
####Moyenne à 0#####
y <- xm - mean(xm)
par(mfrow=c(1,2))
plot(xm)
plot(y)
acf(y,30);pacf(y,30)
#### Test d'integration ####
summary(lm(xm ~ data$Date))
#Cette regression lineaire nous permets de determiner quel type de Dickey-Fuller test nous devons utiliser
#Ici, la constante est significative, et la time trend également,
#nous utiliserons donc  Test for a unit root with constant and deterministic time trend
adf <- adfTest(xm, lag=0, type="ct")
adf
#On rejette donc l'hypothese d'une racine unitaire avec une confiance d'au moins 95%
#On ajoute des differences de lag pour controler l'effet du passe sur la relation entre X_t_-_1 et X_t
Qtests <- function(series, k, fitdf=0) {
pvals <- apply(matrix(1:k), 1, FUN=function(l) {
pval <- if (l<=fitdf) NA else Box.test(series, lag=l, type="Ljung-Box", fitdf=fitdf)$p.value
return(c("lag"=l,"pval"=pval))
})
return(t(pvals))
}
Qtests(adf@test$lm$residuals, 50, fitdf = length(adf@test$lm$coefficients))
#Les résidus sont tous autocorrélés
adfTest_valid <- function(series, kmax, adftype){
k <- 0
noautocorr <- 0
while (noautocorr==0){
cat(paste0("ADF with ",k," lags: residuals OK? "))
adf <- adfTest(series, lags=k, type=adftype)
pvals <- Qtests(adf@test$lm$residuals, kmax, fitdf = length(adf@test$lm$coefficients))[,2]
if (sum(pvals<0.05,na.rm=T)==0) {
noautocorr <- 1; cat("OK \n")
} else cat("nope \n")
k <- k+1
}
return(adf)
}
adf <- adfTest_valid(xm,393,adftype="ct")
Qtests(adf@test$lm$residuals, 393, fitdf = length(adf@test$lm$coefficients))
Qtests(adf@test$lm$residuals, 50, fitdf = length(adf@test$lm$coefficients))
adf <- adfTest(xm, lags=194, type="ct")
Qtests(adf@test$lm$residuals, 393, fitdf = length(adf@test$lm$coefficients))
adf <- adfTest(xm, lags=100, type="ct")
Qtests(adf@test$lm$residuals, 393, fitdf = length(adf@test$lm$coefficients))
Qtests(adf@test$lm$residuals, 194, fitdf = length(adf@test$lm$coefficients))
summary(lm(xm ~ data$Date))
adf <- adfTest(xm, lags=1, type="ct")
adf <- adfTest(xm, lags=10, type="ct")
adf
adf
adfTest(xm, lags=20, type="ct")
adfTest(xm, lags=40, type="ct")
adfTest(xm, lags=50, type="ct")
adfTest(xm, lags=100, type="ct")
adfTest(xm, lags=190, type="ct")
adfTest(xm, lags=200, type="ct")
adfTest(xm, lags=190, type="ct")
summary(lm(dxm ~ dates[-1]))
summary(lm(dxm ~ data$Date[-1]))
adfTest(xm, lags=30, type="ct")
data$Date[-1]
summary(lm(dxm ~ data$Date[-1]))
summary(lm(dxm ~ data$Date))
summary(lm(dxm ~ data$Date))
summary(lm(dxm ~ data$Date[-1]))
#
acf?
#
?acf
#
?acf
#
?[-1]
#
?adfTest_valid
#
adf <- adfTest_valid(dxm,30,"c")
#
adf <- adfTest_valid(dxm,50,"c")
adfTest(dxm, lags=30, type="c")
adfTest(dxm, lags=30, type="nc")
#
adf <- adfTest_valid(dxm,30,"nc")
adfTest(dxm, lags=8, type="nc")
adfTest(dxm, lags=8, type="c")
summary(lm(dxm ~ data$Date[-1]))
#
adf <- adfTest_valid(dxm,50,"nc")
adfTest(dxm, lags=8, type="nc")
par(mfrow=c(1,2))
acf(xm)
axis(side=1,at=seq(0,25))
pacf(xm)
axis(side=1,at=seq(0,25))
y <- xm - mean(xm)
par(mfrow=c(1,2))
plot(xm)
plot(y)
acf(y,30);pacf(y,30)
acf(xm)
axis(side=1,at=seq(0,25))
pacf(xm)
par(mfrow=c(1,2))
acf(xm,30);pacf(x,30)
acf(xm,30);pacf(xm,30)
acf(xm,30);pacf(xm,30)
par(mfrow=c(1,2))
acf(y,30);pacf(y,30)
acf(y,30);pacf(y,30)
#en regardant l'acf je dirais que q= 18 et p=4, m?me si + flou pour le p comme d?passe le seuil ?galement en p=11
# donc tester AR(4), MA(18), and mixed ARMA models. a noter que cette partie nous informe sur les ordres maximums vraisemblables
pmax=4
par(mfrow=c(1,2))
acf(xm,30);pacf(xm,30)
rm(list = ls())
library(zoo) #format de serie temporelle pratique et facile d'utilisation (mais plus volumineux)
library(tseries) #diverses fonctions sur les series temporelles
library(ggplot2)
library(fUnitRoots)
####set-up####
path <- "/Users/ludovic/Desktop/ENSAE/S2/series/serie_temp"
setwd(path) #definit l'espace de travail (working directory ou "wd")
getwd() #affiche le wd
list.files() #liste les elements du wd
####import####
datafile <- "input/valeurs_serie.csv" #definit le fichier de donnees
data <-
read.csv(datafile, sep = ";") #importe un fichier .csv dans un objet de classe data.frame
data <- data[nrow(data):1,]
####representation de la série####
# On enlève les 4 dernière valeurs en vue de la prévision
T <- length(data$Date)
data <- data[-c((T - 3), (T - 2), (T - 1), T),]
# Convertir la colonne "date" en format date et création d'une série de type zoo
data$Date <-
seq(as.Date("1990-05-01"), as.Date("2023-01-01"), by = "1 month") # Convertir la colonne "date" en format date
xm <-
zoo(data$Valeur) # convertit le premiers element de data en serie temporelle de type "zoo"
T <- length(xm)
#data$Date <- seq(as.Date("2023-01-01"), as.Date("1990-05-01"), by = "-1 month")
#xm <- zoo(data$Valeur, order.by=data$Date)
# représentation graphique
dxm <- diff(xm, 1)
plot(cbind(xm, dxm))
ggplot(data, aes(y = xm, x = Date)) +
geom_line()
#ggplot( data, aes(y = xm, x = rev(data$Date))) +
#  geom_line()
####Moyenne à 0#####
y <- xm - mean(xm)
par(mfrow = c(1, 2))
plot(xm)
plot(y)
#### Test d'integration ####
summary(lm(xm ~ data$Date))
#Cette regression lineaire nous permets de determiner quel type de Dickey-Fuller test nous devons utiliser
#Ici, la constante est significative, et la time trend également,
#nous utiliserons donc  Test for a unit root with constant and deterministic time trend
adf <- adfTest(xm, lag = 0, type = "ct")
adf
#On rejette donc l'hypothese d'une racine unitaire avec une confiance d'au moins 95%
#On ajoute des differences de lag pour controler l'effet du passe sur la relation entre X_t_-_1 et X_t
Qtests <- function(series, k, fitdf = 0) {
pvals <- apply(
matrix(1:k),
1,
FUN = function(l) {
pval <- if (l <= fitdf)
NA
else
Box.test(series,
lag = l,
type = "Ljung-Box",
fitdf = fitdf)$p.value
return(c("lag" = l, "pval" = pval))
}
)
return(t(pvals))
}
Qtests(adf@test$lm$residuals, 50, fitdf = length(adf@test$lm$coefficients))
#Les résidus sont tous autocorrélés
adfTest_valid <- function(series, kmax, adftype) {
k <- 0
noautocorr <- 0
while (noautocorr == 0) {
cat(paste0("ADF with ", k, " lags: residuals OK? "))
adf <- adfTest(series, lags = k, type = adftype)
pvals <-
Qtests(adf@test$lm$residuals,
kmax,
fitdf = length(adf@test$lm$coefficients))[, 2]
if (sum(pvals < 0.05, na.rm = T) == 0) {
noautocorr <- 1
cat("OK \n")
} else
cat("nope \n")
k <- k + 1
}
return(adf)
}
adf <- adfTest_valid(xm, 393, adftype = "ct")
adf <- adfTest(xm, lags = 100, type = "ct")
Qtests(adf@test$lm$residuals, 194, fitdf = length(adf@test$lm$coefficients))
#en fait tout nos résidus sont autocorrélés donc pas possible de choisir le bon
#nombre de lag ccar au bout d'un moment on a pluss de degré de liberté
#On va faire un test adf avec le plus de lag qu'on peut
adfTest(xm, lags = 30, type = "ct")
summary(lm(dxm ~ data$Date[-1]))
#
adf <- adfTest_valid(dxm, 50, "nc")
adfTest(dxm, lags = 8, type = "nc")
#série stationnaire en différence première
#il faut donc travailler avec dxm
#Partie 2 identification
par(mfrow = c(1, 2))
acf(xm, 30)
pacf(xm, 30)
#en regardant l'acf je dirais que q= 18 et p=4,
#même si + flou pour le p comme depasse le seuil
#egalement en p=11
# donc tester AR(4), MA(18),
#and mixed ARMA models.
#a noter que cette partie nous informe sur les ordres maximums vraissemblables
pmax = 4
qmax = 18
#fonction de test des significations individuelles des coefficients
signif <-
function(estim) {
coef <- estim$coef
se <- sqrt(diag(estim$var.coef))
t <- coef / se
pval <- (1 - pnorm(abs(t))) * 2
return(rbind(coef, se, pval))
}
## fonction pour estimer un arima et en verifier l'ajustement et la validite
modelchoice <- function(p, q, data = xm, k = 24) {
estim <-
try(arima(data, c(p, 0, q), optim.control = list(maxit = 20000)))
if (class(estim) == "try-error")
return(c(
"p" = p,
"q" = q,
"arsignif" = NA,
"masignif" = NA,
"resnocorr" = NA,
"ok" = NA
))
arsignif <- if (p == 0)
NA
else
signif(estim)[3, p] <= 0.05
masignif <- if (q == 0)
NA
else
signif(estim)[3, p + q] <= 0.05
resnocorr <-
sum(Qtests(estim$residuals, 393, length(estim$coef) - 1)[, 2] <= 0.05, na.rm =
T) == 0
checks <- c(arsignif, masignif, resnocorr)
ok <-
as.numeric(sum(checks, na.rm = T) == (3 - sum(is.na(checks))))
return(
c(
"p" = p,
"q" = q,
"arsignif" = arsignif,
"masignif" = masignif,
"resnocorr" = resnocorr,
"ok" = ok
)
)
}
## fonction pour estimer et verifier tous les arima(p,q) avec p<=pmax et q<=max
armamodelchoice <- function(pmax, qmax) {
pqs <- expand.grid(0:pmax, 0:qmax)
t(apply(matrix(1:dim(pqs)[1]), 1, function(row) {
p <- pqs[row, 1]
q <- pqs[row, 2]
cat(paste0("Computing ARMA(", p, ",", q, ") \n"))
modelchoice(p, q)
}))
}
armamodels <-
armamodelchoice(pmax, qmax)
armamodels
#Maintenant, je conserve que les modeles bien ajustes et valides
selec <-
armamodels[armamodels[, "ok"] == 1 &
!is.na(armamodels[, "ok"]),] #modeles bien ajustes et valides
selec
pqs <-
apply(selec, 1, function(row)
list("p" = as.numeric(row[1]), "q" = as.numeric(row[2]))) #cree une liste des ordres p et q des modeles candidats
pqs
names(pqs) <-
paste0("arma(", selec[, 1], ",", selec[, 2], ")") #renomme les elements de la liste
names
names(pqs)
pqs <-
apply(selec, 1, function(row)
list("p" = as.numeric(row[1]), "q" = as.numeric(row[2]))) #cree une liste des ordres p et q des modeles candidats
names(pqs) <-
paste0("arma(", selec[, 1], ",", selec[, 2], ")") #renomme les elements de la liste
models <-
lapply(pqs, function(pq)
arima(xm, c(pq[["p"]], 0, pq[["q"]]))) #cree une liste des modeles candidats estimes
vapply(models, FUN.VALUE = numeric(2), function(m)
c("AIC" = AIC(m), "BIC" = BIC(m))) #calcule les AIC et BIC des modeles candidats
### L'ARMA(?,?) minimise les criteres d
selec
rm(list = ls())
library(zoo) #format de serie temporelle pratique et facile d'utilisation (mais plus volumineux)
library(tseries) #diverses fonctions sur les series temporelles
library(ggplot2)
library(fUnitRoots)
####set-up####
path <- "/Users/ludovic/Desktop/ENSAE/S2/series/serie_temp"
setwd(path) #definit l'espace de travail (working directory ou "wd")
getwd() #affiche le wd
list.files() #liste les elements du wd
####import####
datafile <- "input/valeurs_serie.csv" #definit le fichier de donnees
data <-
read.csv(datafile, sep = ";") #importe un fichier .csv dans un objet de classe data.frame
data <- data[nrow(data):1,]
####representation de la série####
# On enlève les 4 dernière valeurs en vue de la prévision
T <- length(data$Date)
data <- data[-c((T - 3), (T - 2), (T - 1), T),]
# Convertir la colonne "date" en format date et création d'une série de type zoo
data$Date <-
seq(as.Date("1990-05-01"), as.Date("2023-01-01"), by = "1 month") # Convertir la colonne "date" en format date
xm <-
zoo(data$Valeur) # convertit le premiers element de data en serie temporelle de type "zoo"
T <- length(xm)
#data$Date <- seq(as.Date("2023-01-01"), as.Date("1990-05-01"), by = "-1 month")
#xm <- zoo(data$Valeur, order.by=data$Date)
# représentation graphique
dxm <- diff(xm, 1)
plot(cbind(xm, dxm))
ggplot(data, aes(y = xm, x = Date)) +
geom_line()
